# Introduction to Creating RAGs (Retrieval-Augmented Generators) with OpenAI

Este laboratorio est√° dise√±ado para introducir a los estudiantes a los conceptos fundamentales y la implementaci√≥n pr√°ctica de los Generadores de Recuperaci√≥n Aumentada (RAG) utilizando las herramientas de OpenAI y el framework LangChain. Al finalizar el laboratorio, los estudiantes habr√°n adquirido experiencia pr√°ctica en la creaci√≥n y comprensi√≥n de RAG.

## Getting Started
Estas instrucciones te permitir√°n obtener una copia del proyecto en funcionamiento en tu m√°quina local para prop√≥sitos de desarrollo y pruebas.

### Prerequisites
Para ejecutar este proyecto necesitas:

- python
- pinecone
- longchain
- PyMuPDFLoader

## Overview

Este proyecto implementa un sistema de Generaci√≥n Aumentada de Recuperaci√≥n (RAG) con LangChain, Pinecone y OpenAI. El sistema permite que un chatbot extraiga informaci√≥n relevante de documentos indexados y utilice un LLM (GPT-4) para generar respuestas informadas.

# Parte I

## LangChain LLM Chain & Pinecone Tutorial

## Overview

Este repositorio contiene dos tutoriales b√°sicos:

1. **LangChain LLM Chain**: Implementaci√≥n b√°sica de una canalizaci√≥n de modelos de lenguaje.

2. **Base de datos vectorial Pinecone**: Almacenamiento y recuperaci√≥n de incrustaciones para la b√∫squeda de similitud.

Estos tutoriales proporcionan las bases para construir un sistema avanzado de Recuperaci√≥n-Generaci√≥n Aumentada (RAG).

---

## **Part 1: LangChain**

### **1. Run the chat_model**

![img](img/image.png)

Ejecuta el script:

```bash
python chat_model.py
```

‚úÖ Expected output:

![img](img/image2.png)

---

## üèóÔ∏è **Part 2: Pinecone Vector Database**

### **3Ô∏è. run Pinecone**

![img](img\image3.png)

Ejecuta el script:

```bash
python pinecone_setup.py
```

‚úÖ Expected output:

![img](img\image4.png)

### **5Ô∏è. Query Embeddings**

![img](img\image5.png)

Ejecuta el script:

```bash
python query_pinecone.py
```

‚úÖ Expected output:

![img](img\image6.png)

---

# Parte II
## Architecture

Este proyecto sigue un **enfoque de dos fases**:

1. **Fase de indexaci√≥n** (rag_index.py)
- Carga documentos (PDF/TXT).
- Los divide en fragmentos m√°s peque√±os.
- Genera incrustaciones con OpenAI.
- Los almacena en **Pinecone** para una r√°pida recuperaci√≥n.

2Ô∏è. **Fase de recuperaci√≥n y generaci√≥n** (rag_query.py)
- Recibe una consulta del usuario.
- Busca fragmentos de documentos relevantes en Pinecone.
- Utiliza GPT-4 para generar una respuesta basada en los datos recuperados.

## Installation

### 1. Clonar el repositorio

```bash
git clone https://github.com/Andrea2511/llmAREP.git
cd your-repo
```

### 32. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Set Up Environment Variables

Crear un `.env` archivo con las llaves de API:

```
OPENAI_API_KEY=your-openai-key
PINECONE_API_KEY=your-pinecone-key
PINECONE_ENVIRONMENT=your-pinecone-environment
```

## Running the Project

### **1Ô∏è. Indexing Documents**
Coloca tus documentos en **PDFs and TXT files** dentro de la carpeta `data/` y ejecute el siguiente comando:

```bash
python rag_index.py
```

‚úîÔ∏è Expected output:

```
üìÇ Procesando archivo: document.pdf
‚úÖ document.pdf cargado con 5 documentos.
üìä Se generaron 20 fragmentos para indexar.
‚úÖ 20 fragmentos indexados en Pinecone.
```

### **2Ô∏è. Querying the Chatbot**

```bash
python rag_query.py
```

‚úîÔ∏è Example Interaction:

![img](img/example.png)

## Author

Andrea Valentina Torres Tobar
---

